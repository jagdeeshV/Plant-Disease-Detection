{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8341be5f-e05c-4cb0-a0ef-38fb879468f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.onnx\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import onnx  ## -> installled new\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2015c7fb-f4ff-4eb3-a800-cecb589a6a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes:\n",
      "Apple___Apple_scab\n",
      "Apple___Black_rot\n",
      "Apple___Cedar_apple_rust\n",
      "Apple___healthy\n",
      "Blueberry___healthy\n",
      "Cherry_(including_sour)___healthy\n",
      "Cherry_(including_sour)___Powdery_mildew\n",
      "Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot\n",
      "Corn_(maize)___Common_rust_\n",
      "Corn_(maize)___healthy\n",
      "Corn_(maize)___Northern_Leaf_Blight\n",
      "Grape___Black_rot\n",
      "Grape___Esca_(Black_Measles)\n",
      "Grape___healthy\n",
      "Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\n",
      "Orange___Haunglongbing_(Citrus_greening)\n",
      "Peach___Bacterial_spot\n",
      "Peach___healthy\n",
      "Pepper,_bell___Bacterial_spot\n",
      "Pepper,_bell___healthy\n",
      "Potato___Early_blight\n",
      "Potato___healthy\n",
      "Potato___Late_blight\n",
      "Raspberry___healthy\n",
      "Soybean___healthy\n",
      "Squash___Powdery_mildew\n",
      "Strawberry___healthy\n",
      "Strawberry___Leaf_scorch\n",
      "Tomato___Bacterial_spot\n",
      "Tomato___Early_blight\n",
      "Tomato___healthy\n",
      "Tomato___Late_blight\n",
      "Tomato___Leaf_Mold\n",
      "Tomato___Septoria_leaf_spot\n",
      "Tomato___Spider_mites Two-spotted_spider_mite\n",
      "Tomato___Target_Spot\n",
      "Tomato___Tomato_mosaic_virus\n",
      "Tomato___Tomato_Yellow_Leaf_Curl_Virus\n"
     ]
    }
   ],
   "source": [
    "# The path to the main directory \n",
    "main_dir = r'D:\\Guvi\\FinalPlantproj\\Dataset\\New Plant Diseases Dataset(Augmented)\\train'\n",
    "\n",
    "# List all classes in the main directory\n",
    "classes = [d for d in os.listdir(main_dir) if os.path.isdir(os.path.join(main_dir, d))]\n",
    "\n",
    "# Print the names of the classes\n",
    "print(\"Classes:\")\n",
    "for class_name in classes:\n",
    "    print(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1de4157e-19ce-4898-b7a4-a3ea018a9546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subdirectories ['Apple___Apple_scab', 'Apple___Black_rot', 'Apple___Cedar_apple_rust', 'Apple___healthy', 'Blueberry___healthy', 'Cherry_(including_sour)___healthy', 'Cherry_(including_sour)___Powdery_mildew', 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot', 'Corn_(maize)___Common_rust_', 'Corn_(maize)___healthy', 'Corn_(maize)___Northern_Leaf_Blight', 'Grape___Black_rot', 'Grape___Esca_(Black_Measles)', 'Grape___healthy', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Orange___Haunglongbing_(Citrus_greening)', 'Peach___Bacterial_spot', 'Peach___healthy', 'Pepper,_bell___Bacterial_spot', 'Pepper,_bell___healthy', 'Potato___Early_blight', 'Potato___healthy', 'Potato___Late_blight', 'Raspberry___healthy', 'Soybean___healthy', 'Squash___Powdery_mildew', 'Strawberry___healthy', 'Strawberry___Leaf_scorch', 'Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___healthy', 'Tomato___Late_blight', 'Tomato___Leaf_Mold', 'Tomato___Septoria_leaf_spot', 'Tomato___Spider_mites Two-spotted_spider_mite', 'Tomato___Target_Spot', 'Tomato___Tomato_mosaic_virus', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus'] copied to D:\\Guvi\\FinalPlantproj\\Dataset\\working\n"
     ]
    }
   ],
   "source": [
    "##   B4 running this remove working folder in dataset\n",
    "# List the classes to work on\n",
    "subdirs_to_copy = classes\n",
    "# Create a new directory in the Kaggle working directory\n",
    "subset_dir = 'D:\\Guvi\\FinalPlantproj\\Dataset\\working'\n",
    "os.makedirs(subset_dir, exist_ok=True)\n",
    "\n",
    "# Copy the selected classes to the new directory\n",
    "for subdir_name in subdirs_to_copy:\n",
    "    src_dir_path = os.path.join(main_dir, subdir_name)\n",
    "    dest_dir_path = os.path.join(subset_dir, subdir_name)\n",
    "    shutil.copytree(src_dir_path, dest_dir_path)\n",
    "\n",
    "print(f\"Subdirectories {subdirs_to_copy} copied to {subset_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85a0ac6a-2dbe-4519-b2ca-00465cf3e56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 70295\n"
     ]
    }
   ],
   "source": [
    "# Initialize a counter for the number of images\n",
    "image_count = 0\n",
    "\n",
    "# Iterate over all classes and count the images\n",
    "for subdir, _, files in os.walk(subset_dir):\n",
    "    image_files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff'))]\n",
    "    image_count += len(image_files)\n",
    "\n",
    "print(f\"Total number of images: {image_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feac29d6-d681-4d7d-abb8-b2aeb50036ff",
   "metadata": {},
   "source": [
    "### data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97dce054-cf91-4013-813d-7ce1f910cb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'D:\\Guvi\\FinalPlantproj\\Dataset\\working'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f988f965-5fc8-4b7f-b0ef-4cbbe9d83ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),              # resize all images to 150x150 pixels\n",
    "    transforms.ToTensor(),                      # convert images to PyTorch tensors\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "706096d7-7496-4d28-bcd1-5bb674521beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(dataset_path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "655f8cf7-f875-4a1b-8994-bd2bf5530410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple___Apple_scab',\n",
       " 'Apple___Black_rot',\n",
       " 'Apple___Cedar_apple_rust',\n",
       " 'Apple___healthy',\n",
       " 'Blueberry___healthy',\n",
       " 'Cherry_(including_sour)___Powdery_mildew',\n",
       " 'Cherry_(including_sour)___healthy',\n",
       " 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot',\n",
       " 'Corn_(maize)___Common_rust_',\n",
       " 'Corn_(maize)___Northern_Leaf_Blight',\n",
       " 'Corn_(maize)___healthy',\n",
       " 'Grape___Black_rot',\n",
       " 'Grape___Esca_(Black_Measles)',\n",
       " 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)',\n",
       " 'Grape___healthy',\n",
       " 'Orange___Haunglongbing_(Citrus_greening)',\n",
       " 'Peach___Bacterial_spot',\n",
       " 'Peach___healthy',\n",
       " 'Pepper,_bell___Bacterial_spot',\n",
       " 'Pepper,_bell___healthy',\n",
       " 'Potato___Early_blight',\n",
       " 'Potato___Late_blight',\n",
       " 'Potato___healthy',\n",
       " 'Raspberry___healthy',\n",
       " 'Soybean___healthy',\n",
       " 'Squash___Powdery_mildew',\n",
       " 'Strawberry___Leaf_scorch',\n",
       " 'Strawberry___healthy',\n",
       " 'Tomato___Bacterial_spot',\n",
       " 'Tomato___Early_blight',\n",
       " 'Tomato___Late_blight',\n",
       " 'Tomato___Leaf_Mold',\n",
       " 'Tomato___Septoria_leaf_spot',\n",
       " 'Tomato___Spider_mites Two-spotted_spider_mite',\n",
       " 'Tomato___Target_Spot',\n",
       " 'Tomato___Tomato_Yellow_Leaf_Curl_Virus',\n",
       " 'Tomato___Tomato_mosaic_virus',\n",
       " 'Tomato___healthy']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b4b571-8147-4e0e-8c8c-632b2ae8a091",
   "metadata": {},
   "source": [
    "### train test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28930bee-d789-41c5-8f5f-da0ff427229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, test_idx = train_test_split(list(range(len(dataset))), test_size=0.3, random_state=42)\n",
    "\n",
    "train_dataset = Subset(dataset, train_idx)\n",
    "test_dataset = Subset(dataset, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55ee7803-5f4c-4bf5-807b-e4e3df7726e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(train_dataset, batch_size=15, shuffle=True)\n",
    "testloader = DataLoader(test_dataset, batch_size=15, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c655ecd8-7fbf-4837-80d6-d95bfa95173f",
   "metadata": {},
   "source": [
    "### define cnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b5f7faa-5c26-4e97-b820-899c65174521",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Classification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Classification, self).__init__()\n",
    "\n",
    "        # Convolutional Layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)       # first convolutional layers\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)            # first pooling layer\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)      # second convolutional layer\n",
    "        self.fc1 = nn.Linear(64 * 37 * 37, 128)                                 # 37 x 37 is the size after pooling\n",
    "        self.fc2 = nn.Linear(128, len(dataset.classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)                                                 # flatten all dimensions\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d88f73b3-af3b-412b-9972-1d4bead1af81",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_Model = CNN_Classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9bfd033-1bc5-4bd8-adb3-8a7a5690a189",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(CNN_Model.parameters(), lr=0.001)          # Defines the optimizer, Adam with a learning rate of 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09c5a43-406b-40c2-ab2f-35cb44deac22",
   "metadata": {},
   "source": [
    "### train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d5c85ea-b099-4da7-9304-e6866dab45ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.3677082061767578\n",
      "Epoch 2/10, Loss: 0.4519745111465454\n",
      "Epoch 3/10, Loss: 0.03265060484409332\n",
      "Epoch 4/10, Loss: 0.024218380451202393\n",
      "Epoch 5/10, Loss: 0.0038494367618113756\n",
      "Epoch 6/10, Loss: 1.0418986082077026\n",
      "Epoch 7/10, Loss: 0.004178566392511129\n",
      "Epoch 8/10, Loss: 8.437884389422834e-05\n",
      "Epoch 9/10, Loss: 9.418846457265317e-05\n",
      "Epoch 10/10, Loss: 0.0017746221274137497\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for images, labels in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = CNN_Model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f1b4ef-1858-46c1-ba35-aa22fb16a1d5",
   "metadata": {},
   "source": [
    "### evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d8de45b-8ed6-45cc-97b8-34950b754fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.98 %\n",
      "Precision: 87.5391%\n",
      "Recall: 86.9837%\n",
      "F1-score: 86.9378%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Switch to evaluation mode\n",
    "CNN_Model.eval()\n",
    "\n",
    "# Initialize variables for storing predictions and true labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Correct and total for accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# No gradients needed during evaluation\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "      \n",
    "        # Forward pass to get predictions\n",
    "        outputs = CNN_Model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Update accuracy calculations\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Collect predictions and true labels for other metrics\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy: {accuracy:.2f} %')\n",
    "\n",
    "# Calculate precision, recall, and F1-score using sklearn\n",
    "precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "print(f'Precision: {precision * 100:.4f}%')\n",
    "print(f'Recall: {recall * 100:.4f}%')\n",
    "print(f'F1-score: {f1 * 100:.4f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb30c389-f861-429f-addd-85f904e9af0a",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8cbffd4-3abc-4031-941e-50cec1dc345a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Tomato___healthy\n"
     ]
    }
   ],
   "source": [
    "# Load a test image and preprocess it\n",
    "img = Image.open('D:\\Guvi\\FinalPlantproj\\ANUKSHMITHA0610\\TomatoHealty.JPG')\n",
    "img = transform(img).unsqueeze(0)  # add batch dimension\n",
    "\n",
    "# Pass the image through the model\n",
    "CNN_Model.eval()\n",
    "output = CNN_Model(img)\n",
    "_, predicted = torch.max(output, 1)\n",
    "print(f'Predicted class: {dataset.classes[predicted.item()]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddb5b739-9a9f-43e0-99f3-9ca39466108e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Grape___Esca_(Black_Measles)\n"
     ]
    }
   ],
   "source": [
    "# Load a test image and preprocess it\n",
    "img = Image.open(r'D:\\Guvi\\FinalPlantproj\\Dataset\\New Plant Diseases Dataset(Augmented)\\valid\\Grape___Esca_(Black_Measles)\\02af0429-46c1-444b-bf62-a4d0198141e8___FAM_B.Msls 1062.JPG')\n",
    "img = transform(img).unsqueeze(0)  # add batch dimension\n",
    "\n",
    "# Pass the image through the model\n",
    "CNN_Model.eval()\n",
    "output = CNN_Model(img)\n",
    "_, predicted = torch.max(output, 1)\n",
    "print(f'Predicted class: {dataset.classes[predicted.item()]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4a2945c-a10c-4cb2-baff-26391f604507",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(CNN_Model.state_dict(), 'cnn_model.pth')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04ccef33-f37a-4d62-8e8d-487f3145551f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_Model.load_state_dict(torch.load('cnn_model.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d468077-e233-4a9b-add3-44bd06d69422",
   "metadata": {},
   "source": [
    "### Pretrained models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d44399d-523a-4537-a353-0e31087f3d74",
   "metadata": {},
   "source": [
    "#### Vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e30522ed-0600-4a86-b02b-7619b98c6e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.89 %\n",
      "Precision: 86.2847%\n",
      "Recall: 84.8879%\n",
      "F1-score: 84.4643%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Switch to evaluation mode\n",
    "vgg16.eval()\n",
    "\n",
    "# Initialize variables for storing predictions and true labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "  \n",
    "# Correct and total for accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# No gradients needed during evaluation\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "      \n",
    "        # Forward pass to get predictions\n",
    "        outputs = vgg16(images.to(device))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Update accuracy calculations\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.to(device)).sum().item()\n",
    "        \n",
    "        # Collect predictions and true labels for other metrics\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy: {accuracy:.2f} %')\n",
    "\n",
    "# Calculate precision, recall, and F1-score using sklearn\n",
    "precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "print(f'Precision: {precision * 100:.4f}%')\n",
    "print(f'Recall: {recall * 100:.4f}%')\n",
    "print(f'F1-score: {f1 * 100:.4f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d543db7b-1f40-46f2-89db-c870e9b6b025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\user/.cache\\torch\\hub\\checkpoints\\vgg16-397923af.pth\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 528M/528M [00:50<00:00, 11.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 1.042962670326233\n",
      "Epoch 2/5, Loss: 0.7125754356384277\n",
      "Epoch 3/5, Loss: 1.4591518640518188\n",
      "Epoch 4/5, Loss: 2.754568099975586\n",
      "Epoch 5/5, Loss: 0.8263623118400574\n",
      "Finished Training VGG16\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "# Check if GPU is available and set device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Load pre-trained VGG16 model\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "\n",
    "# Transfer model to the GPU\n",
    "vgg16 = vgg16.to(device)\n",
    "\n",
    "# Freeze all the layers (optional, if you don't want to train the convolutional layers)\n",
    "for param in vgg16.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the classifier to fit the number of classes in your dataset\n",
    "vgg16.classifier[6] = nn.Linear(4096, len(dataset.classes))  # 4096 is the input to the last layer\n",
    "\n",
    "# Transfer classifier changes to the GPU\n",
    "vgg16.classifier = vgg16.classifier.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss().to(device)  # Move criterion to GPU\n",
    "optimizer = optim.Adam(vgg16.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in trainloader:\n",
    "        # Transfer images and labels to GPU\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = vgg16(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
    "\n",
    "print('Finished Training VGG16')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af9edab-c593-49b1-b470-de97251b02eb",
   "metadata": {},
   "source": [
    "### DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ef10b14-3a3b-46f4-9bbe-acdf7e1899b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to C:\\Users\\user/.cache\\torch\\hub\\checkpoints\\densenet121-a639ec97.pth\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 30.8M/30.8M [00:02<00:00, 11.8MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4, Loss: 6.621461391448975\n",
      "Epoch 2/4, Loss: 6.416478633880615\n",
      "Epoch 3/4, Loss: 12.288323402404785\n",
      "Epoch 4/4, Loss: 7.947284075271455e-08\n",
      "Finished Training DenseNet\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "# Check if GPU is available and set device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Load pre-trained DenseNet121 model\n",
    "#densenet = models.densenet121(pretrained=True)\n",
    "densenet = models.densenet121(weights=models.DenseNet121_Weights.DEFAULT)\n",
    "\n",
    "# Transfer model to the GPU\n",
    "densenet = densenet.to(device)\n",
    "\n",
    "# Freeze all the layers if you don't want to train the convolutional layers (optional)\n",
    "for param in densenet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the classifier to fit the number of classes in your dataset\n",
    "num_ftrs = densenet.classifier.in_features\n",
    "densenet.classifier = nn.Linear(num_ftrs, len(dataset.classes))\n",
    "\n",
    "# Transfer classifier changes to the GPU\n",
    "densenet.classifier = densenet.classifier.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss().to(device)  # Move loss function to GPU\n",
    "optimizer = optim.Adam(densenet.parameters(), lr=0.02)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 4\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in trainloader:\n",
    "        # Transfer images and labels to GPU\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = densenet(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
    "\n",
    "print('Finished Training DenseNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78dbe46d-1df3-4a8c-8d61-60f7297b11f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.05 %\n",
      "Precision: 90.49%\n",
      "Recall: 89.05%\n",
      "F1-score: 89.07%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Switch to evaluation model\n",
    "# densenet.eval()\n",
    "\n",
    "# Initialize variables for storing predictions and true labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Correct and total for accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# No gradients needed during evaluation\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "      \n",
    "        # Forward pass to get predictions\n",
    "        outputs = densenet(images.to(device))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Update accuracy calculations\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.to(device)).sum().item()\n",
    "        \n",
    "        # Collect predictions and true labels for other metrics\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy: {accuracy:.2f} %')\n",
    "\n",
    "# Calculate precision, recall, and F1-score using sklearn\n",
    "precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "print(f'Precision: {precision * 100:.2f}%')\n",
    "print(f'Recall: {recall * 100:.2f}%')\n",
    "print(f'F1-score: {f1 * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc81932-791b-4d6d-abb3-394517e6133e",
   "metadata": {},
   "source": [
    "### AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62977ef3-5ffa-4be8-8abc-f9a73206a140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Epoch 1/5, Loss: 0.0\n",
      "Epoch 2/5, Loss: 0.0\n",
      "Epoch 3/5, Loss: 23.71910285949707\n",
      "Epoch 4/5, Loss: 25.55242347717285\n",
      "Epoch 5/5, Loss: 71.16920471191406\n",
      "Finished Training AlexNet\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "# Check if GPU is available and set device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Load pre-trained AlexNet model\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "#alexnet = models.alexnet(weights=models.alexnet_Weights.DEFAULT)\n",
    "\n",
    "\n",
    "# Transfer model to the GPU\n",
    "alexnet = alexnet.to(device)\n",
    "\n",
    "# Freeze layers if desired\n",
    "for param in alexnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the classifier to fit the number of classes in your dataset\n",
    "alexnet.classifier[6] = nn.Linear(4096, len(dataset.classes))\n",
    "\n",
    "# Transfer classifier changes to the GPU\n",
    "alexnet.classifier = alexnet.classifier.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss().to(device)  # Move loss function to GPU\n",
    "optimizer = optim.Adam(alexnet.parameters(), lr=0.02)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in trainloader:\n",
    "        # Transfer images and labels to GPU\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = alexnet(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
    "\n",
    "print('Finished Training AlexNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24867fdd-722e-4208-84ef-97a29076b58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.07 %\n",
      "Precision: 88.75%\n",
      "Recall: 88.07%\n",
      "F1-score: 88.00%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Switch to evaluation model\n",
    "alexnet.eval()\n",
    "\n",
    "# Initialize variables for storing predictions and true labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Correct and total for accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# No gradients needed during evaluation\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "      \n",
    "        # Forward pass to get predictions\n",
    "        outputs = alexnet(images.to(device))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Update accuracy calculations\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.to(device)).sum().item()\n",
    "        \n",
    "        # Collect predictions and true labels for other metrics\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy: {accuracy:.2f} %')\n",
    "\n",
    "# Calculate precision, recall, and F1-score using sklearn\n",
    "precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "print(f'Precision: {precision * 100:.2f}%')\n",
    "print(f'Recall: {recall * 100:.2f}%')\n",
    "print(f'F1-score: {f1 * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41f820c7-deaf-4095-ad70-dfa1791af6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vgg16.state_dict(), 'vgg16.pth')  \n",
    "torch.save(alexnet.state_dict(), 'alexnet_model.pth') \n",
    "torch.save(densenet.state_dict(), 'densenet.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
